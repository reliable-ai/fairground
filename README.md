# FairGround

[![PyPI](https://img.shields.io/pypi/v/fairml-datasets.svg)](https://pypi.org/project/fairml-datasets/)
[![Tests](https://github.com/reliable-ai/fairground/actions/workflows/test.yml/badge.svg)](https://github.com/reliable-ai/fairground/actions/workflows/test.yml)
[![License](https://img.shields.io/badge/license-CC%20BY%204.0-blue.svg)](https://github.com/reliable-ai/fairground/blob/main/LICENSE.md)

<p align="center">
  <img alt="faiground logo" src="https://raw.githubusercontent.com/reliable-ai/fairground/main/docs/assets/fairground-logo-bg.png" width="50%" align="center">
</p>

A comprehensive Python package for loading, processing, and discovering datasets commonly used in algorithmic fairness research. This package provides tools to load datasets, apply preprocessing techniques, and generate relevant metadata for fairness-aware machine learning workflows.

## Installation

Install this library using `pip`:
```bash
pip install fairml-datasets
```

## Usage

The package provides several key functionalities for working with fairness datasets:

### Loading Datasets

```python
from fairml_datasets import datasets

# Load a specific dataset
dataset = datasets.load('adult')

# Get information about available datasets
available_datasets = datasets.list_available()
```

### Generating Metadata

```python
from fairml_datasets import metadata

# Generate metadata for a dataset
meta = metadata.generate(dataset)
```

## CLI Commands

The package also provides command-line tools for common tasks:

### Generating Metadata

```bash
python -m fairml_datasets metadata
```

### Exporting Datasets

```bash
python -m fairml_datasets export-datasets -v raw
```

### Exporting Citations

```bash
python -m fairml_datasets export-citations
```

## Development

To contribute to this library, first checkout the code. Then create a new virtual environment using [uv](https://github.com/astral-sh/uv):

```bash
uv sync --all-extras --dev
```

### Tests

Tests are written using `pytest` and can be run using the following command:

```bash
uv run -m pytest
```

### Formatting

Ruff is used for formatting and linting. Formatting can be automatically checked / applied wherever possible via `ruff check . --fix && ruff format`.

### Documentation

The documentation can be built using mkdocs. Install the documentation dependencies and serve locally:

```bash
uv sync --extra docs
uv run mkdocs serve
```

# License

Due to restrictions in some of the third-party code we include, this work is licensed under two licenses.

The primary license of this work is [Creative Commons Attribution 4.0 International License](./LICENSE.md) (CC BY 4.0). This license applies to all assets generated by the authors of this work. It does NOT apply to the `generate_synthetic_data.py` script, which instead is licensed under GNU GPLv3.

The second license, which applies to the complete repository, is the more restrictive [GNU GENERAL PUBLIC LICENSE 3 (GNU GPLv3)](./LICENSE-2.md).

**Please note that this licensing information only refers to the code, annotations and generated metadata. Individual datasets which are loaded and exported by this package may have different licenses. Please refer to individual datasets and their sources for dataset-level information.**
